{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before you turn this problem in, make sure everything runs as expected. First, **restart the kernel** (in the menubar, select Kernel$\\rightarrow$Restart) and then **run all cells** (in the menubar, select Cell$\\rightarrow$Run All).\n",
    "\n",
    "Make sure you fill in any place that says `YOUR CODE HERE` or \"YOUR ANSWER HERE\", as well as your name and collaborators below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME = \"Hegyi Gáspár András\"\n",
    "COLLABORATORS = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 1: Fisher's and $\\chi^2$-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import scipy.stats\n",
    "import math\n",
    "\n",
    "def assert_approx_equal(value1,value2):\n",
    "    assert np.isclose(value1,value2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A web authoring company uses A/B testing to select the best website design. A/B testing involves creating multiple versions (*A* and *B*) of the website in a campaign to test their effectiveness. Marketers split their audience and direct them to different versions to determine which performs better.\n",
    "\n",
    "\n",
    "**Workflow of A/B testing:**\n",
    "1. **Hypothesis:** Formulate a hypothesis about changes that might improve the click-through rate.\n",
    "2. **Variations:** Create two versions of the original site with specific changes.\n",
    "3. **Traffic Split:** Divide incoming traffic equally between the two website versions.\n",
    "4. **Testing Duration:** Run the test until statistically significant results are obtained.\n",
    "5. **Data Analysis:** Analyze the data to determine which version performs better.\n",
    "\n",
    "When comparing two phenomena (like the efficacy of drugs), we use statistical tests. For comparing, e.g., means of two continuous variables, Student's t-test is used. When we observe counts of occurrences of phenomena, we usually use the $\\chi^2$-test. \n",
    "However, Fisher's exact test is more suitable when the observed counts are small and in the form of a four-field contingency table. \n",
    "\n",
    "A/B testing allows the company to take a scientific approach to marketing.\n",
    "The company prepared two versions of the website, denoted as *A* and *B*. Users who visit the web page are shown one of the two new versions of the page. We will compare the efficacy of the versions *A* and *B*. We observed the number of clicks within the site.\n",
    "The following contingency table summarizes the results. In the table, $N$ denote the total number of visitors, $a$ is the number of visitors who saw the version *A* and followed a link\n",
    "within *A*, $b$ is the number of visitors of version *A* that did not follow \n",
    "any link within the website, ...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Table 1\n",
    "|          | Click YES | Click NO | | Row sum |\t\n",
    "|----------|-----------|----------|-|---------|\n",
    "| Sample A |   $a$     |   $b$    | | $a+b$   |\n",
    "| Sample B |   $c$     |   $d$    | | $c+d$   |\n",
    "|__________|___________|__________| |_________|\n",
    "| Sum      |  $a+c$    |  $b+d$   | | $N$     |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At first, we must formulate the so-called null hypothesis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Samples $A$ and $B$ were taken from the same probability distribution, and the differences between them\n",
    "> were caused by accidents only. In other words, the efficacies of both versions $A$ and $B$ are the same. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1 \n",
    "Assuming that the null hypothesis is true, **derive the formula for computing the probability** that the table with results will have the same values as in *Table 1* for given values $a$, $b$, $c$, and $d$ ($N=a+b+c+d$). \n",
    "\n",
    "**Remarks:**\n",
    "\n",
    "* Stating that the probability corresponds to the hypergeometric probability distributions is insufficient. You should explain the meaning of all binomial coefficients or factorials in the formulas you will use!\n",
    "* You can write the complete derivation of the formula for the probability of *Table 1* by hand and submit it as a scanned picture (or an image captured by, e.g., a mobile phone) in a separate file.\n",
    "* You can get at most **3 points** for this part."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "594300deaf811661d8ba98522495cf92",
     "grade": true,
     "grade_id": "cell-16648fea6d6d33ff",
     "locked": false,
     "points": 3,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "**Here, you can write your answer or the file name where the derivation is.**\n",
    "\n",
    "1. Assume the null hypothesis, that samples A and B are taken from the same probability distribution. We can reformulate the question to what is the probability that `a` people clicked yes on website `A` with the given marginal values. Since the marginal values are known, the other table values (`b,c,d`) are determined.\n",
    "\n",
    "2. Suppose the samples are labeled. If the samples are taken uniformly, it means that there are $n!$ possible orderings if the samples. \n",
    "\n",
    "3. Count the possibilities that there are exactly `a` people clicking on website `A`. Let's say we first get all the samples that click yes, which is (a+c). This means we have to count the possible ways to have `a` number of samples belonging to website `A`. This can be obtained by the combination $(a+c)\\choose a$.\n",
    "\n",
    "4. By the same idea, the possible ways of having `b` people not clicking on website `A` from $b+d$ people who did not click is $(b+d)\\choose b$.\n",
    "\n",
    "5. `a` and `b` samples are chosen for website `A`, however since the samples are labeled there are $(a+b)!$ ways of ordering them. Similarly for website `B`, there are $(c+d)!$ ways of ordering them.\n",
    "\n",
    "6. The final probability is the product of the combinations and permutations, over the permutations of all of the elements. This is the hypergeometric distribution with the variable `a`.  \n",
    "$$P(a_{11} = a)=\\frac{{(a+c)\\choose a} {(b+d)\\choose b} (a+b)!(c+d)!}{n!} = \\frac{{(a+c)\\choose a}{(b+d)\\choose b}}{n\\choose (a+b)}$$  \n",
    "\n",
    "7. Replacing the marginal values with $s_1,s_2$ for the columns and $r_1,r_2$ for the rows,we get the following equation:\n",
    "$$P(a_{11} = a)= \\frac{{s_1\\choose a}{s_2\\choose b}}{n\\choose r_1}=\\frac{{s_1\\choose a}{s_2\\choose b}r_1!r_2!}{n!}= \\frac{s_1!s_2!r_1!r_2!}{n!a!\\left(s_1-a\\right)!b!\\left(s_2-b\\right)!} = \\frac{s_1!s_2!r_1!r_2!}{n!a!b!c!d!} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2\n",
    "In a campaign, the following counts were observed:\n",
    "\n",
    "#### *Table 2*\n",
    "|          | Click YES | Click NO | | Row sum |\t\n",
    "|----------|-----------|----------|-|---------|\n",
    "| Sample A |   4       |   10     | | 14      |\n",
    "| Sample B |   7       |   3      | | 10      |\n",
    "|__________|___________|__________| |_________|\n",
    "| Sum      |  11       |   13     | | 24      |\n",
    "\n",
    "Implement function `table_probability(t)` that computes the probability of *Table 1* (`t` is a 2-by-2 numpy array with the values $a$, $b$, $c$ and $d$ in two rows and two columns) when assuming the null hypothesis is valid, using the formula you have derived in **Task 1**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "78f54d827226f19e5f987a8416768ade",
     "grade": false,
     "grade_id": "cell-9b44f2ab978fdd8d",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def getMarginals(t):\n",
    "    \"\"\"\n",
    "    Returns\n",
    "    -------\n",
    "    s1,s2,r1,r2\n",
    "    \"\"\"\n",
    "    row_sums = np.sum(t,axis=1)\n",
    "    col_sums = np.sum(t,axis = 0)\n",
    "    return col_sums[0],col_sums[1],row_sums[0],row_sums[1]\n",
    "\n",
    "#The equation from task 1, rewritten with the notation(k,N,K,n) of the hypergeometric distribution\n",
    "def hypergeometric(k,N,K,n):\n",
    "    return math.comb(K,k)*math.comb(N-K,n-k)/math.comb(N,n)\n",
    "\n",
    "def table_probability(t):\n",
    "    a = t[0,0]\n",
    "    s1,s2,r1,r2 = getMarginals(t)\n",
    "    N = np.sum(t)\n",
    "    k = a\n",
    "    K = s1\n",
    "    n = r1\n",
    "    return hypergeometric(k,N,K,n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the function, calculate the probability of *Table 2*. Additionally, your implementation should pass all the tests below and some additional hidden tests (**1 point for this part**)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cad5ec6f4471017c67552bade3f69497",
     "grade": true,
     "grade_id": "cell-c4065812a87c7c36",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 4 10]\n",
      " [ 7  3]] has probability 0.04812222371786243\n"
     ]
    }
   ],
   "source": [
    "table = np.array([[5,5], [5,5]])\n",
    "assert_approx_equal(table_probability(table),0.343718)\n",
    "\n",
    "table_2 = np.array([[4, 10], [7, 3]])\n",
    "print(f\"{table_2} has probability {table_probability(table_2)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3\n",
    "\n",
    "The difference between versions *A* and *B* of the website is evident. Is this difference statistically significant? That is, assuming that both samples *A* and *B* are from the same probability distribution, what is the probability that two samples differ to the same or even higher extent? If this probability is small, e.g., at most $\\alpha=0.05$, we can state with high confidence $(1−\\alpha)=0.95$ that the null hypothesis is not valid. Based on the marginal sums ($a+b$, $c+d$, $a+c$, and $b+d$), we can easily compute that the expected value of the field $a$ is approximately $6.16$. The notion of \"differing to the same or even greater extent\" can be understood in two ways:\n",
    "\n",
    "1. one-sided &ndash; only the values of $a$ that are on one side from the expected value; in our case, the values 8 and 9, or\n",
    "2. two-sided &ndash; all the values of $a$ such that $|a−6.16|\\ge 8−6.16$; in our case, the values 0, 1, 2, 3, 4, 8, and 9.\n",
    "  \n",
    "In case 1, we use a one-tailed test; in case 2, we use a two-tailed test.\n",
    "\n",
    "Answer the following question (**1 point**)\n",
    "\n",
    "> **Question:** In general (with sufficient data), which of the four combinations of tests {one-tiled, two-tailed}×\n",
    "{Fisher's test, χ2-test} are meaningful?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "619f34d8b6de390480c639edb95d46a4",
     "grade": true,
     "grade_id": "cell-4715cb1d33d5188c",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "**Your answer goes here.**\n",
    "\n",
    "Two-tailed tests should be used when the distribution we are working with is symmetric, and is converging to 0 on both ends (having 2 tails), and if the distribution is assymetric it is better to use a one-tailed test. A one-tailed test can also be used on one end of a symmetric distribution, however for that we have to know the direction of change in the data, and we have to make sure that checking only one f the tails makes sense.  \n",
    "  \n",
    "So from the above combinations, for the Fisher's test is makes sense to use both one-tailed and two-tailed tests, since it uses a hypergeometric distribution, and for the $\\chi^2$ a one-tailed should be used, since the $\\chi^2$ distribution is assymetric. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using function `table_probability`, implement the function `Fisher_p_value(table, alternative)` that for the contingency table `table` of dimension 2 $\\times$ 2 computes the p-value of Fisher's test. The parameter `alternative` can have only two values:\n",
    "1. For `alternative` equal to 'two-tailed', the function returns the p-value of the two-tailed Fisher's test.\n",
    "2. For `alternative` equal to 'one-tailed', the function returns the p-value of the one-tailed Fisher's test, i.e., the probability that \n",
    "   the observed counts are as seen in `table` or are more extreme &ndash; further from the expected ones *in the same \n",
    "   direction* from the expected counts as `table`. If `table` contains exactly the expected counts, we will consider the direction for the values in the upper left corner less or equal to $a$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "72953bbe811fca6bdaa91871899585c2",
     "grade": false,
     "grade_id": "cell-4373e7a1e9d66569",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def tableProbabilities(t):\n",
    "    \"\"\"\n",
    "    Parameter\n",
    "    -----------\n",
    "    A 2x2 contingency table\n",
    "\n",
    "    Returns\n",
    "    ------------\n",
    "    A list of the probabilities of all the possible tables with the given marginal values.\n",
    "    \"\"\"\n",
    "    marginals= getMarginals(t)\n",
    "    minMarginal = np.argmin(marginals)\n",
    "    s1,s2,r1,r2 = marginals\n",
    "    #Flip rows, columns and the corresponding marginals\n",
    "    if(minMarginal == 1):\n",
    "        t = t[:,[1,0]]\n",
    "        s1,s2 = s2,s1\n",
    "    elif(minMarginal == 3):\n",
    "        t = t[[1,0]]\n",
    "        r1,r2 = r2,r1\n",
    "    N = np.sum(t)\n",
    "    return np.array([table_probability(np.array([[k,r1-k],[s1-k,N+k-s1-r1]])) for k in range(0,marginals[minMarginal]+1)])\n",
    "\n",
    "def Fisher_p_value(table, alternative='two-tailed'):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    -----------\n",
    "    table : A 2x2 cotingency table\n",
    "\n",
    "    alternative: The type of p-value to be calculated, values are \"one-tailed\" or \"two-tailed\"\n",
    "\n",
    "    Returns\n",
    "    ---------\n",
    "    The p-value of the given contingency table\n",
    "    \"\"\"\n",
    "    if table.any()<0:\n",
    "        ValueError(\"Table can not contain negative value!\")\n",
    "    allProbabilities = tableProbabilities(table)\n",
    "    tableProbability = table_probability(table)\n",
    "    if alternative == 'two-tailed':\n",
    "        return sum(allProbabilities[np.where(allProbabilities<=tableProbability)])\n",
    "    ## Else get the minimum value of the table, and sum up all of the tables, where that \n",
    "    ## particular cell contains a lower or equal value to the original value (same as in the slides)\n",
    "    minVal = np.min(table)\n",
    "    minPos = np.argwhere(table == minVal)\n",
    "    # Flip rows and columns, so minimum value is in a_11\n",
    "    if minPos[0,0] == 1:\n",
    "        table = table[[1,0]]\n",
    "    if minPos[0,1] == 1:\n",
    "        table = table[:,[1,0]]\n",
    "    a11,a12,a21,a22 = table[0,0],table[0,1], table[1,0], table[1,1]\n",
    "    tailProbs = [table_probability(np.array([[a11-k,a12+k],[a21+k,a22-k]])) for k in range(0,a11+1)]\n",
    "    return sum(tailProbs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can compute p-values for both alternatives of the Fisher's test for *Table 2*. In the following cell, the function `Fisher_p_value` will be tested (including some hidden tests) and applied on `table_2` (**2 points** of the score)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1b34ce39fe3ec359204d7c583ef182cd",
     "grade": true,
     "grade_id": "cell-de46f8e68caf637c",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p-value of two-tailed Fisher's test for the table\n",
      "t=array([[5, 5],\n",
      "       [5, 5]])\n",
      " is 1.0\n",
      "______________________________\n",
      "p-value of one-tailed Fisher's test for the table\n",
      "t=array([[5, 5],\n",
      "       [5, 5]])\n",
      " is 0.6718591006516703\n",
      "====================\n",
      "p-value of one-tailed Fisher's test for the table\n",
      "t=array([[38,  5],\n",
      "       [20,  9]])\n",
      " is 0.04212893437210189\n",
      "p-value of two-tailed Fisher's test for the table\n",
      "t=array([[38,  5],\n",
      "       [20,  9]])\n",
      " is 0.06678091352515701\n",
      "============================================================\n",
      "============================================================\n",
      "For the table\n",
      "[[ 4 10]\n",
      " [ 7  3]]\n",
      "The p-value of the Fisher's one-tailed test is 0.05505451608561045\n",
      "The p-value of the Fisher's two-tailed test is 0.09530219410418629\n"
     ]
    }
   ],
   "source": [
    "t = np.array([[5,5], [5,5]])\n",
    "alternative = 'two-tailed'\n",
    "p = Fisher_p_value(t, alternative)\n",
    "print(f\"p-value of {alternative} Fisher's test for the table\\n{t=}\\n is {p}\")\n",
    "assert_approx_equal(p, 1.0)\n",
    "\n",
    "print('_'*30)\n",
    "\n",
    "t = np.array([[5,5], [5,5]])\n",
    "alternative = 'one-tailed'\n",
    "p = Fisher_p_value(t, alternative)\n",
    "print(f\"p-value of {alternative} Fisher's test for the table\\n{t=}\\n is {p}\")\n",
    "assert_approx_equal(p, 0.6718591)\n",
    "\n",
    "print('='*20)\n",
    "\n",
    "t = np.array([[38,5], [20,9]])\n",
    "alternative = 'one-tailed'\n",
    "p = Fisher_p_value(t, alternative)\n",
    "print(f\"p-value of {alternative} Fisher's test for the table\\n{t=}\\n is {p}\")\n",
    "assert_approx_equal(p, 0.042128934)\n",
    "\n",
    "alternative = 'two-tailed'\n",
    "p = Fisher_p_value(t, alternative)\n",
    "print(f\"p-value of {alternative} Fisher's test for the table\\n{t=}\\n is {p}\")\n",
    "assert_approx_equal(p, 0.0667809135)\n",
    "\n",
    "print(\"=\"*60 + \"\\n\" + \"=\"*60)\n",
    "one_tailed_Fisher_p_value = Fisher_p_value(table_2, 'one-tailed')\n",
    "two_tailed_Fisher_p_value = Fisher_p_value(table_2, 'two-tailed')\n",
    "print(f\"For the table\\n{table_2}\")\n",
    "print(f\"The p-value of the Fisher's one-tailed test is {one_tailed_Fisher_p_value}\")\n",
    "print(f\"The p-value of the Fisher's two-tailed test is {two_tailed_Fisher_p_value}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While ignoring the requirement that the χ2-test can be used only if all expected counts in the contingency table are at least 5, for all meaningful combinations of the χ2-test for *Table 2* compute χ2-statistics and its corresponding p-value.\n",
    "\n",
    "For computing the χ2-test use suitable functions from the Python `scipy` module like `scipy.stats.chi2.pdf()`, `scipy.stats.chi2.cdf()`, `scipy.stats.chi2.sf()`, and `scipy.stats.chi2.isf()`. Your code should end with storing the value of the χ2-statistics of any of the meaningful combinations into variable `x2_stat` and its corresponsing p-value in the variable `x2_p_value`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4c6a56633217a82b3774c7b793148849",
     "grade": false,
     "grade_id": "cell-48899b24bcc3ccc2",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# here goes your code for computing  χ2-test using suitable functions \n",
    "# from the Python scipy module like scipy.stats.chi2.cdf(), \n",
    "# scipy.stats.chi2.sf() and scipy.stats.chi2.isf()\n",
    "# BUT NOT scipy.stats.chi2_contingency()\n",
    "def expectedTable(table):\n",
    "    s1,s2,r1,r2 = getMarginals(table)\n",
    "    n = np.sum(table)\n",
    "    return np.outer([r1,r2],[s1,s2])/n\n",
    "\n",
    "def chi2Stat(table):\n",
    "    expected = expectedTable(table)\n",
    "    return np.sum(np.power(table-expected,2.0)/expected)    \n",
    "\n",
    "x2_stat = chi2Stat(table_2)\n",
    "\n",
    "dof = (table_2.shape[0]-1)*(table_2.shape[1]-1)\n",
    "x2_p_value = 1-scipy.stats.chi2.cdf(x2_stat,dof) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " In the following cell, your results (`x2_stat` and `x2_p_value`) will be evaluated (**1 point**)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a6bc102463b0d31f4c0a6f69fb260ad9",
     "grade": true,
     "grade_id": "cell-6d0c6efb3129999f",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x2_stat=4.032767232767235\n",
      "x2_p_value=0.04462468800071262\n"
     ]
    }
   ],
   "source": [
    "# here, your solution will be evaluated\n",
    "print(f\"{x2_stat=}\")\n",
    "print(f\"{x2_p_value=}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, `scipy` contains functions for computing Fisher's exact test and χ2-test. Compute the above tests for *Table 2* using the functions `scipy.stats.fisher_exact()` and `scipy.stats.chi2_contingency()`  (**1 point**)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a46222db94789dc187976239cb22de5b",
     "grade": true,
     "grade_id": "cell-5976302d9d823e68",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The two-tailed Fisher's test on table2 with statistics 0.17142857142857143 and p-value 0.0953021941041863\n",
      "The less one-tailed Fisher's test on table2 with statistics 0.17142857142857143 and p-value 0.05505451608561045\n",
      "The greater one-sided Fisher's test on table2 with statistics: 0.17142857142857143 and p-value 0.9930677076322519\n"
     ]
    }
   ],
   "source": [
    "#Fisher's tests\n",
    "fishersTwoSided = scipy.stats.fisher_exact(table_2)\n",
    "fishersLess = scipy.stats.fisher_exact(table_2,\"less\")\n",
    "fishersGreater = scipy.stats.fisher_exact(table_2,\"greater\")\n",
    "print(f\"The two-tailed Fisher's test on table2 with statistics {fishersTwoSided.statistic} and p-value {fishersTwoSided.pvalue}\")\n",
    "print(f\"The less one-tailed Fisher's test on table2 with statistics {fishersLess.statistic} and p-value {fishersLess.pvalue}\")\n",
    "print(f\"The greater one-sided Fisher's test on table2 with statistics: {fishersGreater.statistic} and p-value {fishersGreater.pvalue}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The X2 test's statistics without Yates correction on table2 is 4.032767232767235 and p-value is 0.04462468800071265\n",
      "The corrected X2 test's statistics on table2 is 2.5366633366633375 and p-value is 0.11122961808080513\n"
     ]
    }
   ],
   "source": [
    "#X2 tests\n",
    "x2 = scipy.stats.chi2_contingency(table_2,correction = False)\n",
    "print(f\"The X2 test's statistics without Yates correction on table2 is {x2.statistic} and p-value is {x2.pvalue}\")\n",
    "\n",
    "x2Corrected = scipy.stats.chi2_contingency(table_2)\n",
    "print(f\"The corrected X2 test's statistics on table2 is {x2Corrected.statistic} and p-value is {x2Corrected.pvalue}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final evaluation\n",
    "\n",
    "1. State explicitly whether we can or cannot reject the null hypothesis for each test you have performed for *Table 2*.\n",
    "2. Further, compare the results obtained with your implementation of the tests and the results obtained when using the functions \n",
    "   `scipy.stats.fisher_exact()` and `scipy.stats.chi2_contingency()`. If there are any differences, explain them (**1 point**). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "dea0f364da51362369e6edc57bb64873",
     "grade": true,
     "grade_id": "cell-d6071350659ec21b",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "**Answer**\n",
    "\n",
    "1. Since `Table 2` is a 2X2 contingency table, I am using the results from the Fisher's test to determine whether we can or cannot reject the null hypothesis. In case of Fisher's test, if the p-value is lower than the significance level $\\alpha$, the null hypothesis is rejected. With the two-tailed p-value $\\approx 0.095$, and significance level $\\alpha = 0.05$, we can not reject the null hypothesis, which means that the tests on the clicks on the different websites were drawn from the same distribution, i.e. the efficacies of the two websites are the same. We can arrive to the same conclusion with the one-tailed test.\n",
    "  \n",
    "2. The results that are obtained from the scipy.stats package have multiple different arguments. \n",
    "    - The `scipy.stats.chi2_contingency()` has an argument for the Yates correction which moves the table's values by 0.5 in order to correct the error introduced by assuming that the table probabilities can be described using a continuous $\\chi^2$ distribution. Setting the argument to false, the results are the same as in my implementation.\n",
    "    - The `scipy.stats.fisher_exact()` has argument $alternative$ for the calculation of the p-value. These are two-tailed, less, or greater. The latter two options decide the one-tailed p-value's direction. Choosing the value two-tailed , or the less has the same results as my implementation with the corresponding alternatives.\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b69a0928c92c0b0e42f38df67d4dfafe1423e04848311fa5ae6e94359e52488d"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

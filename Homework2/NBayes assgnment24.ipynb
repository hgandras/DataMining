{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before you turn this problem in, make sure everything runs as expected. First, **restart the kernel** (in the menubar, select Kernel$\\rightarrow$Restart) and then **run all cells** (in the menubar, select Cell$\\rightarrow$Run All).\n",
    "\n",
    "Make sure you fill in any place that says `YOUR CODE HERE` or \"YOUR ANSWER HERE\", as well as your name and collaborators below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME = \"Hegyi Gáspár András\"\n",
    "COLLABORATORS = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment: Naïve Bayes Classifier\n",
    "\n",
    "In this assignment, you will implement the Naïve Bayes classifier and compare it to that one implemented `scikit-learn` module. The goal is to investigate the influence of Laplace correction on the classification results for the Naïve Bayes classifier.\n",
    "\n",
    "As a sample dataset, we will use the MNIST dataset of handwritten digits quantized into vectors of length 784, where each element of a vector is the gray level of the corresponding picture pixel. The original pictures have dimensions 28$\\times$28. All vectors contain only pixels with three possible values: 0,1,2. The value 2 indicates a black pixel, the value 0 corresponds to a white pixel, and the value 1 corresponds to a gray pixel.\n",
    "\n",
    "The file `MNIST3_dataset.npz` with the dataset can be downloaded from Moodle together with this notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['X_train', 'X_validate', 'X_test', 'y_train', 'y_validate', 'y_test']"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# in the load method the parameter allow_pickle must \n",
    "# be set to True for unpacking the data\n",
    "npzfile = np.load('MNIST3_v1_dataset.npz', allow_pickle=True)\n",
    "npzfile.files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The arrays `X_train` and `y_train` contain training input data and true classes. The arrays `X_validate` and `y_validate` contain validation input data and true classes. The arrays `X_test` and `y_test` contain test inputs and true labels. E.g., let us inspect the 34th test sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True label 7\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 200x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "s = 34\n",
    "plt.figure(figsize=(2,2))\n",
    "plt.imshow(npzfile['X_test'][s].reshape(28,28), cmap='Greys')\n",
    "y_test = npzfile['y_test']\n",
    "print('True label',y_test[s])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should implement your own Naïve Bayes classifier for classifying the handwritten digits. For that, you **must not use any classifier from another toolbox or library**. You should implement the following two functions:\n",
    "* `NBTrain` for training a Naïve Bayes classifier with a Laplace correction, and\n",
    "* `NBClassify` for classification.\n",
    "\n",
    "After implementing the functions, you should test your classifier on the test \n",
    "set of handwritten digits. Below you will find a detailed description of the functions you should implement and tests you should perform."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: Implement the function `NBTrain()`\n",
    "\n",
    "The first function is \n",
    "\n",
    "    NBTrain(Pat, PatClass, FNum, CNum, LC=0)\n",
    "    \n",
    "where \n",
    "* `Pat` are training patterns stored in a two-dimensional array of integers with values between 0 and `FNum-1`,\n",
    "* `PatClass` are true classes of the patterns in the array `Pat`; that is, `PatClass[i]` is the true class for the pattern `Pat[i]`,\n",
    "* `FNum`is the number of possible values for a feature, the features can have values between 0 and `FNum-1` only, we assume `FNum` $\\le10$,\n",
    "* `CNum` is the number of classes, `PatClass` can contain only values between 0 and `CNum-1` (we assume `CNum` $\\le 20$), and\n",
    "* `LC` is the value of Laplace correction.\n",
    "\n",
    "Function `NBTrain` should return a pair `(B,P)` of tables:\n",
    "* `B` is a three-dimensional array, where `B[f,i,c]` is the **logarithm** of the probability that a pattern with value `f` in feature `i` is classified into the class `c`. For computing this conditional probability, you should use Laplace correction in the following form \n",
    "\n",
    "$B[f,i,c] = \\log\\frac{\\text{the number of pattern with classification } c \\text{ and value } f \\text{ in the element } i \\text{ of the pattern} + LC}{\\text{the number of patterns from class } c + FNum\\cdot LC}$\n",
    "\n",
    "*  `P` is an array of log priors &ndash; **logarithms** of the estimates of apriori probabilities for all classes (without the Laplace correction)\n",
    "\n",
    "$$P[c] = \\log \\frac{\\text{the number of patterns classified into class } c}{\\text{the number of all patterns}}\\ .$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d90fcd0685910bc6e4d944f96fdc56e3",
     "grade": false,
     "grade_id": "cell-893037a547e8a2de",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def NBTrain(Pat, PatClass, FNum, CNum, LC=0):\n",
    "    # the function computes two tables for the Naïve Bayes classifier\n",
    "    # Parameters:\n",
    "    #    Pat      training patterns stored in a two-dimensional \n",
    "    #             numpy array of integers with values between 0 and FNum-1\n",
    "    #    PatClass true classes of the patterns in the array Pat, \n",
    "    #             integers between 0 to CNum-1\n",
    "    #    FNum     the number of possible values for a feature, \n",
    "    #             the features can have values between 0 and FNum-1\n",
    "    #    CNum     the number of classes\n",
    "    #    LC       the value (float) of Laplace correction\n",
    "    # Returns a pair (B,P) of tables:\n",
    "    #    B        a three-dimensional array, where B[f,i,c] is the \n",
    "    #             **base-2 logarithm** of the probability that a pattern with value f\n",
    "    #             in feature i is classified into the class c. \n",
    "    #             For computing this conditional probability, the Laplace \n",
    "    #             correction LC should be used \n",
    "    #    P        an array of log priors; P[c] is the (base-2 logarithm) of the prior\n",
    "    #             probability that a sample will be from the class c\n",
    "    numEntries = Pat.shape[0]\n",
    "    numFeatures = Pat.shape[1]\n",
    "    counts = np.zeros((FNum,numFeatures,CNum),dtype = np.float64)\n",
    "    classCounts = np.zeros(CNum,dtype=np.float64)\n",
    "\n",
    "    for c,element in enumerate(Pat):\n",
    "        elementClass = PatClass[c]\n",
    "        classCounts[elementClass]+=1 #Count the specific class\n",
    "        classIndices = np.repeat(elementClass,numFeatures)\n",
    "        featureIndices = np.arange(numFeatures)\n",
    "        np.add.at(counts,(element,featureIndices,classIndices),1)\n",
    "    priors = np.log2(classCounts/numEntries)\n",
    "\n",
    "    counts += LC\n",
    "    classCounts += FNum*LC\n",
    "    return  np.log2(counts/classCounts),priors\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us try the implementation on a tiny dataset of three samples with two attributes:\n",
    "\n",
    "Attr1 |\tAttr2 |\tClass\n",
    "------|-------|------\n",
    "0 |     0 |   0\n",
    "1 |     0 |   0   \n",
    "2 |     1 |   1\n",
    "\n",
    "The following cell will test your implementation of `NBTrain`, including several **hidden tests** (you can obtain **3 points**).\n",
    "\n",
    "*Note: Warning `RuntimeWarning: divide by zero encountered in log ...`  is O.K.*, but you can turn it off by calling\n",
    "\n",
    "    np.seterr(divide = 'ignore')\n",
    "\n",
    "and back\n",
    "\n",
    "    np.seterr(divide = 'warn') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "21352cf6f4ba38dd6c175565f94081c5",
     "grade": true,
     "grade_id": "cell-1fe26e02dd5dda04",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "B=array([[[ -1., -inf],\n",
      "        [  0., -inf]],\n",
      "\n",
      "       [[ -1., -inf],\n",
      "        [-inf,   0.]],\n",
      "\n",
      "       [[-inf,   0.],\n",
      "        [-inf, -inf]]])\n",
      "P=array([-0.5849625, -1.5849625])\n",
      "\n",
      "B=array([[[-1.32192809, -2.        ],\n",
      "        [-0.73696559, -2.        ]],\n",
      "\n",
      "       [[-1.32192809, -2.        ],\n",
      "        [-2.32192809, -1.        ]],\n",
      "\n",
      "       [[-2.32192809, -1.        ],\n",
      "        [-2.32192809, -2.        ]]])\n",
      "P=array([-0.5849625, -1.5849625])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hgand\\AppData\\Local\\Temp\\ipykernel_21928\\3793682572.py:36: RuntimeWarning: divide by zero encountered in log2\n",
      "  return  np.log2(counts/classCounts),priors\n"
     ]
    }
   ],
   "source": [
    "X = np.array([[0,0],\n",
    "              [1,0],\n",
    "              [2,1]])\n",
    "y = np.array([0,0,1])\n",
    "\n",
    "B, P = NBTrain(X, y, 3, 2, LC=0)\n",
    "print(f\"\\n{B=}\\n{P=}\")\n",
    "assert np.allclose(B[1], np.array([[    -1., -np.inf],\n",
    "                                   [-np.inf,      0.]]))\n",
    "assert np.allclose(P, np.array([-0.5849625, -1.5849625]))\n",
    "\n",
    "B, P = NBTrain(X, y, 3, 2, LC=1)\n",
    "print(f\"\\n{B=}\\n{P=}\")\n",
    "assert np.allclose(B[2], np.array([[-2.32192809, -1.        ],\n",
    "                                   [-2.32192809, -2.        ]]))\n",
    "assert np.allclose(P, np.array([-0.5849625, -1.5849625]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: Implement the function `NBClassify()`\n",
    "\n",
    "The second function \n",
    "\n",
    "    NBClassify(Pat, B, P)\n",
    "\n",
    "computes the classification of the patterns `Pat` based on tables `B` and `P` produced by the function `NBTrain` and using the method of Naïve Bayes classifier. Its parameters are\n",
    "* `Pat` is a two-dimensional array of patterns (each row of `Pat` is one pattern),\n",
    "* `B` is a three-dimensional array of floats - the first array computed by `NBTrain`, and\n",
    "* `P` is a vector of floats - the second array computed by `NBTrain`.\n",
    "\n",
    "The function returns a vector containing predicted classes for all patterns from `Pat`.\n",
    "\n",
    "In the implementation, you should use a logarithm, as otherwise, by computing products of a large number of values less than one, the accuracy can be lost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5977531e0208db19256a44bff8b96588",
     "grade": false,
     "grade_id": "cell-4560197cd66bb962",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def NBClassify(Pat, B, P):\n",
    "    # using the method of Naïve Bayes classifier, computes \n",
    "    # the classification of the patterns Pat \n",
    "    # based on tables B and P produced by the function NBTrain\n",
    "    # Parameters:\n",
    "    #   Pat a two-dimensional array of patterns (each row of Pat is one pattern),\n",
    "    #   B   a three-dimensional array of floats - the first array computed by NBTrain, and\n",
    "    #   P   a vector of floats - the second array computed by NBTrain.\n",
    "    # Returns: a vector containing predicted classes for all patterns from Pat.\n",
    "    # 1. Calculate the probabilities for the entry as a sum of logarithms for all possible classes\n",
    "    # 2. Take power of the logs\n",
    "    # 3. Find the maximum value (that will be the class the entry belongs to)\n",
    "    numClasses = P.shape[0]\n",
    "    numEntries = Pat.shape[0]\n",
    "    numFeatures = Pat.shape[1]\n",
    "    predicts = np.zeros((numEntries,numClasses),dtype = np.float64)\n",
    "\n",
    "    featureIndices = np.arange(numFeatures)\n",
    "    for i,entry in enumerate(Pat):\n",
    "        predicts[i] += P + np.sum(B[entry,featureIndices],axis=0)\n",
    "\n",
    "    return np.argmax(predicts,axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following cell, your implemenation will be tested using also **hidden tests**. Do not edit the cell. You can obtain **3 points** for your implementation.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8d3e34c270dee540b04185866e527124",
     "grade": true,
     "grade_id": "cell-643921bc7937c7dd",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-3.33963722 -3.14586069 -3.33235307 -3.28461616 -3.3623063  -3.47329013\n",
      " -3.34022154 -3.26395803 -3.35934206 -3.33963722]\n",
      "[9 5 1 ... 0 0 4]\n",
      "True classes [8 5 1 ... 0 0 4]\n",
      "Accuracy: 0.8366\n"
     ]
    }
   ],
   "source": [
    "B, P = NBTrain(npzfile['X_train'], npzfile['y_train'], 3, 10, 1)\n",
    "print(P)\n",
    "X_train = npzfile['X_train']\n",
    "c = NBClassify(npzfile['X_train'],B,P)\n",
    "print(c)\n",
    "print('True classes',npzfile['y_train'])\n",
    "print(f\"Accuracy: {np.sum(c == npzfile['y_train'])/ c.shape[0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.83666\n"
     ]
    }
   ],
   "source": [
    "#My testing whether the scikit implementation does better than mine with the same Laplace smoothing\n",
    "from sklearn.naive_bayes import CategoricalNB\n",
    "\n",
    "nb = CategoricalNB()\n",
    "nb.fit(npzfile[\"X_train\"],npzfile[\"y_train\"])\n",
    "results = nb.predict(npzfile[\"X_train\"])\n",
    "print(f\"Accuracy: {np.sum(results == npzfile['y_train'])/ results.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3: Find the best classifier\n",
    "\n",
    "There are two sub-tasks here:\n",
    "\n",
    "1. Calculate the error of the classifier on the validation set `X_validate` and the test set `X_test` for different Naïve bayes classifiers trained on `X_train` with different values of Laplace correction `LC` = 0, 0.00001, 0.0001, 0.0005, 0.001, 0.002, 0.005, 0.01, 0.1, 0.2, 0.4, 1. For which of these Laplace correction values is the error on the validation set minimal?\n",
    "\n",
    "3. Describe the errors made by your best obtained classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement the following function that selects the value of Laplace correction from the given list for which the accuracy of the classifier on the validation set is maximal. The function should return the selected Laplace correction and a two-dimensional array with rows of the form\n",
    "\n",
    "(*lc*, *train_a*, *validate_a*, *test_a*)\n",
    "\n",
    "where \n",
    "* *lc* is a value of Laplace correction from the given list,\n",
    "* *train_a* is the accuracy of the Naïve Bayes classifier with the Laplace correction *lc* on the train set,\n",
    "* *validate_a* is the accuracy of the Naïve Bayes classifier with the Laplace correction *lc* on the validation set,\n",
    "* *train_a* is the accuracy of the Naïve Bayes classifier with the Laplace correction *lc* on the test set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6d9e042585a22de4c011b5c2d164f2c6",
     "grade": false,
     "grade_id": "cell-e00a9b78db8fa3be",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def best_LC(X_train, y_train, X_validate, y_validate, X_test, y_test, FNum, CNum, lc_list=[0.0]):\n",
    "    # Using NBTrain and NBClassify, find the value of Laplace correction from the list\n",
    "    # lc_list for which the classifier trained on X_train with true classes y_train\n",
    "    # has the highest accuracy on the validation set X_validate with true classes y_validate\n",
    "    # Parameters:\n",
    "    #   X_train    a two-dimensional numpy array of patterns (each row is one pattern),\n",
    "    #   y_train    a one-dimensional numpy array of integers with correct classes for \n",
    "    #              the patterns in X_train,\n",
    "    #   X_validate a two-dimensional numpy array of patterns (each row is one pattern),\n",
    "    #   y_validate a one-dimensional numpy array of integers with correct classes for \n",
    "    #              the patterns in X_validate,\n",
    "    #   FNum       the number of possible values for a feature, \n",
    "    #              the features can have values between 0 and FNum-1\n",
    "    #   CNum       the number of classes\n",
    "    #   LC_list    a list of values of Laplace correction\n",
    "    # Returns:     one value from LC_list that is the best Laplace correction; \n",
    "    #              if the best accuracy is achieved for more than one Laplace correction\n",
    "    #              from the list lc_list, the function returns the leftmost one in lc_list\n",
    "    result = np.zeros((3,len(lc_list)))\n",
    "    result = np.concatenate([np.array([lc_list]),result],axis=0)\n",
    "    for c,lc in enumerate(lc_list):\n",
    "        B,P = NBTrain(X_train,y_train,FNum,CNum,lc)\n",
    "        predTrainClasses = NBClassify(X_train,B,P)\n",
    "        predValClasses = NBClassify(X_validate,B,P)\n",
    "        predTestClasses = NBClassify(X_test,B,P)\n",
    "        accuracyTrain = np.sum(predTrainClasses == y_train)/ predTrainClasses.shape[0]\n",
    "        accuracyVal = np.sum(predValClasses == y_validate)/ predValClasses.shape[0]\n",
    "        accuracyTest = np.sum(predTestClasses == y_test)/ predTestClasses.shape[0]\n",
    "        result[1,c]+=accuracyTrain\n",
    "        result[2,c]+=accuracyVal\n",
    "        result[3,c]+= accuracyTest\n",
    "\n",
    "    return lc_list[np.min(np.argmax(result[2]))],result.T\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following cell, the function `best_LC` will be tested, including **hidden tests** (you can obtain **2 points**). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "82cffccb9bea12d29d71f20850aade3e",
     "grade": true,
     "grade_id": "cell-b9874d63bd3092ea",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best Laplace correction for mini-dataset 0.1\n",
      "   Laplace correction  Train accuracy  Validation accuracy  Test accuracy\n",
      "0                 0.0            1.00                 0.05           0.15\n",
      "1                 0.1            1.00                 0.45           0.45\n",
      "2                 0.5            1.00                 0.40           0.30\n",
      "3                 1.0            0.85                 0.35           0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hgand\\AppData\\Local\\Temp\\ipykernel_21928\\3793682572.py:36: RuntimeWarning: divide by zero encountered in log2\n",
      "  return  np.log2(counts/classCounts),priors\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "K = 20\n",
    "X_train = npzfile['X_train'][:2 * K]\n",
    "X_validate = npzfile['X_validate'][:K]\n",
    "X_test = npzfile['X_test'][:K]\n",
    "y_train = npzfile['y_train'][:2 * K]\n",
    "y_validate = npzfile['y_validate'][:K]\n",
    "y_test = npzfile['y_test'][:K]\n",
    "\n",
    "best_lc, table = best_LC(X_train, y_train, X_validate, y_validate, X_test, y_test, 3, 10, lc_list=[0.0, 0.1, 0.5, 1.0])\n",
    "print(f\"The best Laplace correction for mini-dataset {best_lc}\")\n",
    "\n",
    "assert best_lc == 0.1\n",
    "df = pd.DataFrame(table, columns=['Laplace correction', 'Train accuracy', 'Validation accuracy', 'Test accuracy'])\n",
    "print(df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next cell, find the best Laplace correction for the complete dataset obtained from the file `MNIST3_v1_dataset.npz`(with respect to the accuracy on the validation set) to variable `lc` and the corresponding accuracy on the test set to variable `accuracy'. Use the list `lc_list = [0, 0.00001, 0.0001, 0.0005, 0.001, 0.002, 0.005, 0.01, 0.1, 0.2, 0.4, 1]` as the set of possible values of the Laplace correction.\n",
    "\n",
    "Additionally, print the table obtained from the corresponding call to `best_LC`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "015b01c03c188cb99e1c90bd255b6074",
     "grade": false,
     "grade_id": "cell-3b0c3622b157700f",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hgand\\AppData\\Local\\Temp\\ipykernel_21928\\3793682572.py:36: RuntimeWarning: divide by zero encountered in log2\n",
      "  return  np.log2(counts/classCounts),priors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Laplace correction  Train accuracy  Validation accuracy  Test accuracy\n",
      "0              0.00000         0.84116               0.8337         0.8468\n",
      "1              0.00001         0.83990               0.8357         0.8491\n",
      "2              0.00010         0.83950               0.8358         0.8490\n",
      "3              0.00050         0.83920               0.8357         0.8489\n",
      "4              0.00100         0.83908               0.8354         0.8488\n",
      "5              0.00200         0.83900               0.8354         0.8486\n",
      "6              0.00500         0.83876               0.8354         0.8485\n",
      "7              0.01000         0.83854               0.8353         0.8485\n",
      "8              0.10000         0.83792               0.8352         0.8479\n",
      "9              0.20000         0.83770               0.8350         0.8480\n",
      "10             0.40000         0.83730               0.8345         0.8477\n",
      "11             1.00000         0.83660               0.8339         0.8471\n"
     ]
    }
   ],
   "source": [
    "lc_list = [0.0, 0.00001, 0.0001, 0.0005, 0.001, 0.002, 0.005, 0.01, 0.1, 0.2, 0.4, 1.0]\n",
    "\n",
    "lc,table = best_LC(npzfile[\"X_train\"],npzfile[\"y_train\"],npzfile['X_validate'],npzfile['y_validate'],npzfile['X_test'],npzfile['y_test'],3,10,lc_list)\n",
    "\n",
    "df = pd.DataFrame(table, columns=['Laplace correction', 'Train accuracy', 'Validation accuracy', 'Test accuracy'])\n",
    "print(df)\n",
    "\n",
    "accuracy =df['Test accuracy'].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following cell, the values of `lc` and `accuracy` will be tested (**1 point**)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take the best Naïve Bayes classifier for the complete dataset and plot the first 10 images with digits from the test set, for which the classifier made an error. For each image, print the classification computed by the classifier and the correct classification. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "27883c87442767c1accd7fb1e39c0830",
     "grade": false,
     "grade_id": "cell-ea77dcd6358977bd",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Real\n",
      "4 5\n",
      "3 5\n",
      "4 6\n",
      "0 4\n",
      "3 2\n",
      "3 1\n",
      "2 6\n",
      "8 0\n",
      "2 3\n",
      "9 4\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "B,P = NBTrain(npzfile[\"X_train\"],npzfile[\"y_train\"],3,10,lc)\n",
    "wrongClass = 0\n",
    "fig,axs = plt.subplots(2,5)\n",
    "print(\"Predicted Real\")\n",
    "for c,sample in enumerate(npzfile[\"X_test\"]):\n",
    "    c_pred = NBClassify(np.array([sample]),B,P)\n",
    "    c_real = npzfile[\"y_test\"][c]\n",
    "    if c_pred[0]!=c_real:\n",
    "        print(c_pred[0],c_real)\n",
    "        axs[wrongClass//5,wrongClass%5].imshow(np.reshape(sample,(28,28)),cmap=\"gray\")\n",
    "        wrongClass+=1\n",
    "\n",
    "    if(wrongClass==10):\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "400a03aff124e5db3835f003eafb751a",
     "grade": false,
     "grade_id": "cell-f6a5d063cd3c5f1a",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": true
    }
   },
   "source": [
    "Try to explain the errors made by the classifier. (**1 point**)\n",
    "\n",
    "I would say the error happens when the digit resembles another digit, and probably there is only a slight difference in the log likelihoods\n",
    "between the real and the predicted class.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
